{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mBERT_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzdVNgKiP1yw",
        "colab_type": "code",
        "outputId": "b2bd2029-a3d6-4d59-dcfa-a68bc260cd7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "\"\"\"\n",
        "Start by detecting what kind of GPU Google Colab gave you \n",
        "\"\"\"\n",
        "\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=9a7ebf7ce0b809dac57b107b2258367f9efd85d43d1a6c45164fca79030aa359\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 157.5 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3RBEaepDY1U",
        "colab_type": "code",
        "outputId": "e0c1f468-df0b-49b6-d482-69187b28a795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "\"\"\"\n",
        "Simulation data. This gives you an idea of the data that is expect. \n",
        "The data we expect is in the following format\n",
        "\"\"\"\n",
        "import pandas as pd \n",
        "\n",
        "df = pd.DataFrame()\n",
        "y = [0 for _ in range(10)] + [1 for _ in range(10)]\n",
        "x = ['english' for _ in range(10)] + ['francais' for _ in range(10)]\n",
        "\n",
        "df['txt'] = x \n",
        "df['labels'] = y \n",
        "\n",
        "ratio_anomaly = 0.2\n",
        "N_nor = 10 \n",
        "N_an = int(N_nor * ratio_anomaly / (1-ratio_anomaly))\n",
        "\n",
        "df.sort_values(by = 'labels', ascending = True, inplace = True)\n",
        "\n",
        "df.tail(N_an + N_nor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>english</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>english</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>francais</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         txt  labels\n",
              "1    english       0\n",
              "4    english       0\n",
              "18  francais       1\n",
              "10  francais       1\n",
              "11  francais       1\n",
              "12  francais       1\n",
              "13  francais       1\n",
              "14  francais       1\n",
              "15  francais       1\n",
              "16  francais       1\n",
              "17  francais       1\n",
              "19  francais       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Oe9K_ITlTm",
        "colab_type": "code",
        "outputId": "8b08586e-f38f-4a78-ff84-5171bb0fda71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "N_an + N_nor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkwn5nluUSfX",
        "colab_type": "code",
        "outputId": "5adf13ab-df88-4bfa-ac8b-f307bbbbd140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "! git clone https://MastafaF:password@github.com/MastafaF/multilingual_bert_classification.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'multilingual_bert_classification'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 53 (delta 24), reused 42 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-AhI6FZn12j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir(\"multilingual_bert_classification\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91IauRhADcSn",
        "colab_type": "code",
        "outputId": "00cb3356-e650-47b5-8c34-78cb0390b4fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "! pip install transformers\n",
        "! pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 6.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 16.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=26bfd51076fbb087d23fb9ddaadfa8cfbd2e5406d4228d6f09206d51caa88c5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wQhwaVto-pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.chdir(\"../\")\n",
        "# ! rm -rf multilingual_bert_classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3xQ3UcLn8D1",
        "colab_type": "code",
        "outputId": "e848ee93-60bc-499b-b209-993db4e0897b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_classifier.py  embedding.py  requirements.txt  test.py   utils\n",
            "data\t\t    README.md\t  save\t\t    train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GAhBJekCVpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.chdir(\"../\")\n",
        "# ! rm -rf model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5neoIjZYn81O",
        "colab_type": "code",
        "outputId": "7b12b0bc-826b-48e8-9831-e31037d5d64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "! python train.py --gpu --data_path data/ --save_path save/ --lr 5e-5 --batch_size 16 --epochs 4 --plot_path save/plot/ --bert_model bert-base-multilingual-cased --anomaly_ratio 0.005"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(anomaly_ratio=0.005, batch_size=16, bert_model='bert-base-multilingual-cased', data_path='data/', epochs=4, gpu=True, load_dataset_from_pickle=False, load_frompretrain=False, lr=5e-05, model_config_path='None', model_state_path='None', plot_path='save/plot/', save_path='save/', test_ratio=0.2, val_ratio=0.2, zero_shot_data_path=None)\n",
            "22968\n",
            "/content/multilingual_bert_classification/utils/data_reader.py:92: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train.sort_values(by = 'labels', ascending = True, inplace = True)\n",
            "3446\n",
            "4594\n",
            "4594\n",
            "==== Distribution of training set ====\n",
            "Number of anomalies: 17\n",
            "Percentage of anomalies 0.4933255948926245%\n",
            "Number of normal: 3429\n",
            "=======================================\n",
            "Epoch 0\n",
            "Iteration: 100% 216/216 [01:43<00:00,  2.32it/s]\n",
            "Evaluating: 100% 288/288 [00:26<00:00, 10.92it/s]\n",
            "\n",
            "F1 score evaluation: 0.733057051566141, Accuracy: 0.7631693513278189\n",
            "epoch 0 loss train: 0.047560894953811064\n",
            "Saving model to save//model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064\n",
            "Epoch 1\n",
            "Iteration: 100% 216/216 [01:46<00:00,  2.31it/s]\n",
            "Evaluating: 100% 288/288 [00:26<00:00, 12.50it/s]\n",
            "\n",
            "F1 score evaluation: 0.5732241104139104, Accuracy: 0.5925119721375708\n",
            "epoch 1 loss train: 0.03333845836351867\n",
            "Saving model to save//model/epoch-1-0.5925119721375708-0.5732241104139104-0.03333845836351867\n",
            "Epoch 2\n",
            "Iteration: 100% 216/216 [01:46<00:00,  2.28it/s]\n",
            "Evaluating: 100% 288/288 [00:25<00:00, 11.09it/s]\n",
            "\n",
            "F1 score evaluation: 0.4033803855384482, Accuracy: 0.42207226817588156\n",
            "epoch 2 loss train: 0.001890248055638545\n",
            "Saving model to save//model/epoch-2-0.42207226817588156-0.4033803855384482-0.001890248055638545\n",
            "Epoch 3\n",
            "Iteration: 100% 216/216 [01:47<00:00,  2.31it/s]\n",
            "Evaluating: 100% 288/288 [00:26<00:00, 12.52it/s]\n",
            "\n",
            "F1 score evaluation: 0.4059827545810927, Accuracy: 0.4244666956900305\n",
            "epoch 3 loss train: 5.815927813643982e-05\n",
            "Saving model to save//model/epoch-3-0.4244666956900305-0.4059827545810927-5.815927813643982e-05\n",
            "Evaluating: 100% 288/288 [00:25<00:00, 12.46it/s]\n",
            "running\n",
            "Using GPU to make things faster :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maprvn9ipLT-",
        "colab_type": "code",
        "outputId": "21f42dc5-5d38-49d6-d642-cd6611c22831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "! python test.py --gpu --load_frompretrain --model_state_path  /content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064 --model_config_path /content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064/config.json --data_path data/ --save_path save/ --lr 5e-5 --batch_size 16 --epochs 5 --plot_path save/plot/ --bert_model bert-base-multilingual-cased --anomaly_ratio 0.10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(anomaly_ratio=0.1, batch_size=16, bert_model='bert-base-multilingual-cased', data_path='data/', epochs=5, gpu=True, load_dataset_from_pickle=False, load_frompretrain=True, lr=5e-05, model_config_path='/content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064/config.json', model_state_path='/content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064', plot_path='save/plot/', save_path='save/', test_ratio=0.2, val_ratio=0.2, zero_shot_data_path=None)\n",
            "22968\n",
            "/content/multilingual_bert_classification/utils/data_reader.py:92: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train.sort_values(by = 'labels', ascending = True, inplace = True)\n",
            "3810\n",
            "4594\n",
            "4594\n",
            "==== Distribution of training set ====\n",
            "Number of anomalies: 381\n",
            "Percentage of anomalies 10.0%\n",
            "Number of normal: 3429\n",
            "=======================================\n",
            "Evaluating: 100% 288/288 [00:24<00:00, 11.90it/s]\n",
            "BERT classifier, F1 score is 0.7439969776682416\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     anomaly       1.00      0.68      0.81      3450\n",
            "      normal       0.51      1.00      0.68      1144\n",
            "\n",
            "    accuracy                           0.76      4594\n",
            "   macro avg       0.75      0.84      0.74      4594\n",
            "weighted avg       0.88      0.76      0.78      4594\n",
            "\n",
            "running\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uo7NhHXrUNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Zero-Shot Learning \n",
        "with open(\"/content/multilingual_bert_classification/data/harry_potter.tok.ru\",\n",
        "          mode=\"rt\", encoding=\"utf-8\") as f:\n",
        "    s_normal = [line.rstrip() for line in f if len(line.split()) > 5] # filter out on the fly short sentences \n",
        "\n",
        "labels_arr = [1 for _ in range(len(s_normal))]\n",
        "\n",
        "# Build a test dataframe with only Russian harry potter which we expect to be predicted as Normal\n",
        "df_test_multilingual = pd.DataFrame()\n",
        "df_test_multilingual['txt'] = s_normal\n",
        "df_test_multilingual['labels'] = labels_arr \n",
        "\n",
        "df_test_multilingual.to_csv(\"/content/multilingual_bert_classification/data/df_multilingual.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyKJ_gIo4Dcv",
        "colab_type": "code",
        "outputId": "32858e4b-3fba-438f-b960-b79d7b7391ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "! python zero_shot_test.py --zero_shot_data_path /content/multilingual_bert_classification/data/df_multilingual.tsv --gpu --load_frompretrain --model_state_path  /content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064  --model_config_path /content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064/config.json --data_path data/ --save_path save/ --lr 5e-5 --batch_size 16 --epochs 5 --plot_path save/plot/ --bert_model bert-base-multilingual-cased --anomaly_ratio 0.10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(anomaly_ratio=0.1, batch_size=16, bert_model='bert-base-multilingual-cased', data_path='data/', epochs=5, gpu=True, load_dataset_from_pickle=False, load_frompretrain=True, lr=5e-05, model_config_path='/content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064/config.json', model_state_path='/content/multilingual_bert_classification/save/model/epoch-0-0.7631693513278189-0.733057051566141-0.047560894953811064', plot_path='save/plot/', save_path='save/', test_ratio=0.2, val_ratio=0.2, zero_shot_data_path='/content/multilingual_bert_classification/data/df_multilingual.tsv')\n",
            "22968\n",
            "/content/multilingual_bert_classification/utils/data_reader.py:92: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train.sort_values(by = 'labels', ascending = True, inplace = True)\n",
            "3810\n",
            "4594\n",
            "4594\n",
            "==== Distribution of training set ====\n",
            "Number of anomalies: 381\n",
            "Percentage of anomalies 10.0%\n",
            "Number of normal: 3429\n",
            "=======================================\n",
            "Evaluating: 100% 20/20 [00:01<00:00, 12.01it/s]\n",
            "BERT classifier, F1 score is 0.4837662337662338\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     anomaly       0.00      0.00      0.00         0\n",
            "      normal       1.00      0.94      0.97       318\n",
            "\n",
            "    accuracy                           0.94       318\n",
            "   macro avg       0.50      0.47      0.48       318\n",
            "weighted avg       1.00      0.94      0.97       318\n",
            "\n",
            "running\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L77W8xcV6AgD",
        "colab_type": "code",
        "outputId": "1e3ce94a-71b1-478e-8062-0b3065c0d682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import pandas as pd \n",
        "pd.read_csv(\"./data/df.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>txt</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22673</td>\n",
              "      <td>same answer which you were about to give me then.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24142</td>\n",
              "      <td>this is he who being the greatest tyrant of hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3132</td>\n",
              "      <td>but winky cried harder than ever.  dobby, on t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17831</td>\n",
              "      <td>from without; there let them encamp, and when ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11142</td>\n",
              "      <td>to the number of days and nights in a year (36...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22963</th>\n",
              "      <td>2577</td>\n",
              "      <td>mademoiselle delacour, could we have you first...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22964</th>\n",
              "      <td>23407</td>\n",
              "      <td>at gymnastics; sometimes idling and neglecting...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22965</th>\n",
              "      <td>8830</td>\n",
              "      <td>been the ruin of many an army. there is meanne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22966</th>\n",
              "      <td>16193</td>\n",
              "      <td>what is to be done then? i said; how shall we ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22967</th>\n",
              "      <td>17796</td>\n",
              "      <td>children of the earth and their own brothers.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22968 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                                                txt  labels\n",
              "0           22673  same answer which you were about to give me then.       0\n",
              "1           24142  this is he who being the greatest tyrant of hi...       0\n",
              "2            3132  but winky cried harder than ever.  dobby, on t...       1\n",
              "3           17831  from without; there let them encamp, and when ...       0\n",
              "4           11142  to the number of days and nights in a year (36...       0\n",
              "...           ...                                                ...     ...\n",
              "22963        2577  mademoiselle delacour, could we have you first...       1\n",
              "22964       23407  at gymnastics; sometimes idling and neglecting...       0\n",
              "22965        8830  been the ruin of many an army. there is meanne...       0\n",
              "22966       16193  what is to be done then? i said; how shall we ...       0\n",
              "22967       17796      children of the earth and their own brothers.       0\n",
              "\n",
              "[22968 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}